{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     active environment : nbai\n    active env location : C:\\Users\\percy\\anaconda3\\envs\\nbai\n"
     ]
    }
   ],
   "source": [
    "# Active env should say \"nbai\"\n",
    "!conda info | grep 'active env'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datetime import datetime\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from src.graph_format import NbaDatabase, NbaPosessionDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4584520\n"
     ]
    }
   ],
   "source": [
    "database = NbaPosessionDatabase(range(2001, 2020))\n",
    "\n",
    "print(len(database))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "train_size = int(len(database) * 0.9)\n",
    "val_size = len(database) - train_size\n",
    "train_set, val_set = torch.utils.data.random_split(database, [train_size, val_size])\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=3200, shuffle=True, pin_memory=use_cuda, num_workers=4)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=3200, shuffle=True, pin_memory=use_cuda, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pownet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(pownet, self).__init__()\n",
    "        self.bn = nn.BatchNorm1d(6)\n",
    "        self.order_1 = nn.Linear(2, 1, bias=True)\n",
    "        self.order_2 = nn.Linear(2, 1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for _ in range(10):\n",
    "            x[:, 4][x[:, 4] <= 0] += 300 # overtime\n",
    "        time_left = (x[:, 4:5] / 2880.0)\n",
    "        x[:, 2][x[:, 2] > 6] = 6\n",
    "        x[:, 3][x[:, 3] > 6] = 6\n",
    "        x = self.bn(x)\n",
    "        score_diff = x[:, 0] - x[:, 1]\n",
    "        penalty_diff = x[:, 2] - x[:, 3]\n",
    "        time_feature = x[:, 4:5]\n",
    "        state_vec = torch.stack((score_diff, penalty_diff), dim=1)\n",
    "        order_1 = self.order_1(state_vec)\n",
    "        order_2 = self.order_2(state_vec) / torch.sqrt(time_left)\n",
    "        out = torch.sigmoid(order_1 + order_2)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "net = pownet()\n",
    "net = net.to(device)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=1e-1, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1e-4, max_lr=1e-1, step_size_up=30)"
   ]
  },
  {
   "source": [
    "running_loss = 0\n",
    "for epoch in range(60):\n",
    "    epoch_start = datetime.now()\n",
    "    for start_state, _, label in train_loader:\n",
    "        start_prob = net(start_state.to(device))\n",
    "        #end_prob = net(end_state.to(device))\n",
    "        loss = criterion(start_prob, label.to(device))# + criterion(end_prob, label.to(device))\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        scheduler.step()\n",
    "    seconds = int((datetime.now() - epoch_start).total_seconds())\n",
    "    print(f\"e{epoch}:\\tloss {running_loss:.3f}\\ttime {seconds}\\tlabel {label[0].item()}\\tpred {start_prob[0].item():.3f}\\tfeat{start_state[0].long().tolist()}\")\n",
    "    running_loss = 0\n"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 27,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "e0:\tloss 652.994\ttime 405\tlabel 0.0\tpred 0.194\tfeat[16, 29, 4, 2, 2185, 1]\n",
      "e1:\tloss 646.142\ttime 393\tlabel 0.0\tpred 0.010\tfeat[55, 82, 5, 6, 868, 1]\n",
      "e2:\tloss 646.017\ttime 384\tlabel 1.0\tpred 0.704\tfeat[82, 78, 2, 5, 871, 1]\n",
      "e3:\tloss 645.806\ttime 381\tlabel 0.0\tpred 0.569\tfeat[2, 0, 0, 0, 2803, 1]\n",
      "e4:\tloss 645.779\ttime 384\tlabel 0.0\tpred 0.126\tfeat[69, 78, 1, 2, 570, 1]\n",
      "e5:\tloss 645.627\ttime 383\tlabel 0.0\tpred 0.414\tfeat[47, 49, 6, 3, 1527, 1]\n",
      "e6:\tloss 645.635\ttime 385\tlabel 0.0\tpred 0.605\tfeat[14, 12, 0, 5, 2417, 1]\n",
      "e7:\tloss 645.648\ttime 381\tlabel 0.0\tpred 0.553\tfeat[62, 62, 1, 2, 952, 1]\n",
      "e8:\tloss 645.486\ttime 382\tlabel 1.0\tpred 0.435\tfeat[49, 52, 3, 6, 1541, 1]\n",
      "e9:\tloss 645.519\ttime 379\tlabel 0.0\tpred 0.041\tfeat[73, 88, 1, 1, 565, 1]\n",
      "e10:\tloss 645.654\ttime 382\tlabel 0.0\tpred 0.064\tfeat[51, 67, 1, 2, 965, 1]\n",
      "e11:\tloss 645.607\ttime 385\tlabel 1.0\tpred 0.753\tfeat[68, 61, 3, 3, 1131, 1]\n",
      "e12:\tloss 645.404\ttime 379\tlabel 0.0\tpred 0.070\tfeat[74, 88, 0, 0, 702, 1]\n",
      "e13:\tloss 645.378\ttime 384\tlabel 1.0\tpred 0.435\tfeat[44, 46, 3, 3, 1648, 1]\n",
      "e14:\tloss 645.357\ttime 382\tlabel 0.0\tpred 0.531\tfeat[20, 19, 3, 0, 2256, 1]\n",
      "e15:\tloss 645.494\ttime 382\tlabel 0.0\tpred 0.107\tfeat[84, 93, 3, 6, 361, 1]\n",
      "e16:\tloss 645.389\ttime 382\tlabel 1.0\tpred 0.999\tfeat[102, 90, 6, 6, 105, 1]\n",
      "e17:\tloss 645.348\ttime 380\tlabel 0.0\tpred 0.196\tfeat[9, 21, 6, 3, 2306, 1]\n",
      "e18:\tloss 645.367\ttime 381\tlabel 1.0\tpred 0.998\tfeat[103, 93, 3, 2, 91, 1]\n",
      "e19:\tloss 645.386\ttime 383\tlabel 1.0\tpred 0.990\tfeat[89, 78, 4, 5, 188, 1]\n",
      "e20:\tloss 645.290\ttime 381\tlabel 0.0\tpred 0.448\tfeat[8, 11, 2, 2, 2611, 1]\n",
      "e21:\tloss 645.357\ttime 383\tlabel 0.0\tpred 0.149\tfeat[92, 98, 1, 3, 257, 1]\n",
      "e22:\tloss 645.312\ttime 383\tlabel 1.0\tpred 0.373\tfeat[39, 43, 4, 1, 1746, 1]\n",
      "e23:\tloss 645.257\ttime 384\tlabel 0.0\tpred 0.454\tfeat[79, 80, 4, 5, 126, 1]\n",
      "e24:\tloss 645.342\ttime 382\tlabel 1.0\tpred 0.498\tfeat[22, 23, 3, 3, 2256, 1]\n",
      "e25:\tloss 645.413\ttime 382\tlabel 1.0\tpred 0.539\tfeat[20, 19, 2, 2, 2344, 1]\n",
      "e26:\tloss 645.345\ttime 382\tlabel 0.0\tpred 0.499\tfeat[47, 47, 5, 3, 1505, 1]\n",
      "e27:\tloss 645.300\ttime 382\tlabel 1.0\tpred 0.967\tfeat[90, 73, 4, 6, 839, 1]\n",
      "e28:\tloss 645.502\ttime 381\tlabel 0.0\tpred 0.085\tfeat[46, 63, 0, 0, 1395, 1]\n",
      "e29:\tloss 645.385\ttime 382\tlabel 0.0\tpred 0.767\tfeat[91, 88, 4, 4, 273, 1]\n",
      "e30:\tloss 645.223\ttime 385\tlabel 0.0\tpred 0.663\tfeat[8, 2, 0, 0, 2768, 1]\n",
      "e31:\tloss 645.347\ttime 382\tlabel 1.0\tpred 0.571\tfeat[13, 11, 2, 1, 2492, 1]\n",
      "e32:\tloss 645.312\ttime 382\tlabel 1.0\tpred 0.242\tfeat[17, 28, 2, 2, 2258, 1]\n",
      "e33:\tloss 645.389\ttime 384\tlabel 1.0\tpred 0.525\tfeat[35, 35, 0, 1, 2062, 1]\n",
      "e34:\tloss 645.387\ttime 383\tlabel 0.0\tpred 0.320\tfeat[24, 31, 0, 1, 1945, 1]\n",
      "e35:\tloss 645.322\ttime 383\tlabel 0.0\tpred 0.037\tfeat[70, 83, 1, 3, 353, 1]\n",
      "e36:\tloss 645.369\ttime 383\tlabel 1.0\tpred 0.882\tfeat[97, 94, 6, 6, 83, 1]\n",
      "e37:\tloss 645.190\ttime 382\tlabel 0.0\tpred 0.188\tfeat[21, 34, 2, 4, 1887, 1]\n",
      "e38:\tloss 645.250\ttime 381\tlabel 1.0\tpred 1.000\tfeat[93, 86, 5, 5, 18, 1]\n",
      "e39:\tloss 645.355\ttime 382\tlabel 0.0\tpred 0.279\tfeat[71, 77, 0, 0, 720, 1]\n",
      "e40:\tloss 645.334\ttime 383\tlabel 1.0\tpred 0.853\tfeat[43, 30, 1, 2, 1960, 1]\n",
      "e41:\tloss 645.284\ttime 380\tlabel 0.0\tpred 0.498\tfeat[8, 8, 0, 0, 2680, 1]\n",
      "e42:\tloss 645.315\ttime 382\tlabel 0.0\tpred 0.206\tfeat[32, 44, 0, 2, 2057, 1]\n",
      "e43:\tloss 645.290\ttime 382\tlabel 0.0\tpred 0.019\tfeat[48, 73, 3, 1, 1126, 1]\n",
      "e44:\tloss 645.376\ttime 382\tlabel 0.0\tpred 0.016\tfeat[65, 84, 1, 2, 528, 1]\n",
      "e45:\tloss 645.220\ttime 381\tlabel 0.0\tpred 0.472\tfeat[14, 15, 3, 1, 2436, 1]\n",
      "e46:\tloss 645.206\ttime 386\tlabel 0.0\tpred 0.672\tfeat[9, 2, 1, 0, 2736, 1]\n",
      "e47:\tloss 645.213\ttime 382\tlabel 1.0\tpred 0.358\tfeat[50, 54, 3, 3, 1052, 1]\n",
      "e48:\tloss 645.253\ttime 382\tlabel 0.0\tpred 0.318\tfeat[85, 88, 2, 3, 403, 1]\n",
      "e49:\tloss 645.227\ttime 398\tlabel 1.0\tpred 0.996\tfeat[115, 90, 1, 1, 644, 1]\n",
      "e50:\tloss 645.216\ttime 392\tlabel 1.0\tpred 0.496\tfeat[9, 9, 3, 1, 2524, 1]\n",
      "e51:\tloss 645.313\ttime 386\tlabel 1.0\tpred 0.620\tfeat[39, 36, 1, 1, 1856, 1]\n",
      "e52:\tloss 645.251\ttime 382\tlabel 0.0\tpred 0.382\tfeat[2, 7, 1, 0, 2740, 1]\n",
      "e53:\tloss 645.188\ttime 381\tlabel 1.0\tpred 0.599\tfeat[73, 71, 6, 2, 752, 1]\n",
      "e54:\tloss 645.279\ttime 383\tlabel 0.0\tpred 0.327\tfeat[34, 40, 3, 3, 1853, 1]\n",
      "e55:\tloss 645.230\ttime 380\tlabel 0.0\tpred 0.000\tfeat[101, 112, 5, 4, 46, 1]\n",
      "e56:\tloss 645.264\ttime 382\tlabel 1.0\tpred 0.677\tfeat[60, 55, 0, 0, 1382, 1]\n",
      "e57:\tloss 645.179\ttime 380\tlabel 0.0\tpred 0.047\tfeat[82, 91, 6, 6, 199, 1]\n",
      "e58:\tloss 645.354\ttime 382\tlabel 1.0\tpred 0.305\tfeat[52, 58, 0, 0, 1413, 1]\n",
      "e59:\tloss 645.282\ttime 382\tlabel 0.0\tpred 0.769\tfeat[69, 65, 4, 1, 371, 1]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 678 loss\n",
    "trained_net = net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=5, microseconds=391649)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}